{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"말뭉치_짧은문장_테스트.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ZOK6isNNeLVh5jw0RGaarNDcoznJsZvQ","authorship_tag":"ABX9TyNXpD0UDkyHwujPCZGKzIhB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"927ePE5U5cEL","executionInfo":{"status":"ok","timestamp":1651308193318,"user_tz":-540,"elapsed":47244,"user":{"displayName":"이진하","userId":"09853356890937709334"}},"outputId":"cacbe37f-9639-4fb1-d50a-1c3d82c40a9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 133 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 153 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 174 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 184 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 215 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 235 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 245 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 256 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 266 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 276 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 286 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 296 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 307 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 317 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 327 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 337 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 344 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.28)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.8)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595738 sha256=9405003fe8cf56e19b994ef71dff7325353125395e7ce1780ba8c0f2574a5214\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.0)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 36.4 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 46.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 35.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.8.1rc1 transformers-3.0.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-p66hh5zq\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-p66hh5zq\n","Collecting boto3\n","  Downloading boto3-1.22.4-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n","Collecting mxnet>=1.4.0\n","  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n","\u001b[K     |████████████████████████████████| 47.3 MB 1.3 MB/s \n","\u001b[?25hCollecting onnxruntime==1.8.0\n","  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 41.2 MB/s \n","\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.11.0+cu113)\n","Collecting transformers>=4.8.1\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.28)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (4.2.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.64.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.49)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 30.8 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 38.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.11.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.8)\n","Collecting botocore<1.26.0,>=1.25.4\n","  Downloading botocore-1.25.4-py3-none-any.whl (8.7 MB)\n","\u001b[K     |████████████████████████████████| 8.7 MB 40.8 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.4->boto3->kobert==0.2.3) (2.8.2)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 63.9 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.26.0,>=1.25.4->boto3->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.8.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15674 sha256=ab9ced2b7d3127e696a6ce2da93b97b994e0f356cf78b286adcaf97663a9594a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-uzq08gu6/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","Successfully built kobert\n","Installing collected packages: urllib3, jmespath, pyyaml, botocore, tokenizers, s3transfer, huggingface-hub, graphviz, transformers, onnxruntime, mxnet, boto3, kobert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.8.1rc1\n","    Uninstalling tokenizers-0.8.1rc1:\n","      Successfully uninstalled tokenizers-0.8.1rc1\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 3.0.2\n","    Uninstalling transformers-3.0.2:\n","      Successfully uninstalled transformers-3.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.22.4 botocore-1.25.4 graphviz-0.8.4 huggingface-hub-0.5.1 jmespath-1.0.0 kobert-0.2.3 mxnet-1.9.0 onnxruntime-1.8.0 pyyaml-6.0 s3transfer-0.5.2 tokenizers-0.12.1 transformers-4.18.0 urllib3-1.25.11\n"]}],"source":["!pip install gluonnlp pandas tqdm\n","!pip install transformers==3.0.2\n","!pip install torch\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"]},{"cell_type":"code","source":["!pip install mxnet\n","!pip install sentencepiece"],"metadata":{"id":"vHg89ziowiIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","#kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#GPU 사용\n","#device = torch.device(\"cuda:0\")\n","device = torch.device(\"cpu\")\n","\n","#BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpBjAmE95hKt","executionInfo":{"status":"ok","timestamp":1651308229103,"user_tz":-540,"elapsed":32090,"user":{"displayName":"이진하","userId":"09853356890937709334"}},"outputId":"093d19ab-d9c3-4b42-a885-5b141e880c9a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","source":["# KoBERT 모델에 맞는 입력 데이터 형태로 변경\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"metadata":{"id":"Q-hf6n7w5rIA","executionInfo":{"status":"ok","timestamp":1651308229349,"user_tz":-540,"elapsed":3,"user":{"displayName":"이진하","userId":"09853356890937709334"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 모델 정의\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=6,   # 클래스 수 조정\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"metadata":{"id":"VSyJ3hZ15tJB","executionInfo":{"status":"ok","timestamp":1651308229349,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진하","userId":"09853356890937709334"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["## 학습 모델 로드\n","PATH = '/content/drive/MyDrive/대학/캡스톤/'\n","model = torch.load(PATH + '말뭉치_짧은문장_KoBERT_2.pt', map_location=device)  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n","model.load_state_dict(torch.load(PATH + '말뭉치_짧은문장_state_dict_2.pt', map_location=device))  # state_dict를 불러 온 후, 모델에 저장\n","\n","#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9prE5k4t5vIC","executionInfo":{"status":"ok","timestamp":1651308263148,"user_tz":-540,"elapsed":8747,"user":{"displayName":"이진하","userId":"09853356890937709334"}},"outputId":"af57d6e1-2248-4566-cac5-ece58ca9198d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}]},{"cell_type":"code","source":["# Setting parameters\n","max_len = 96\n","batch_size = 32\n","warmup_ratio = 0.1\n","num_epochs = 10\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate = 5e-5"],"metadata":{"id":"J0c08D5-6RXA","executionInfo":{"status":"ok","timestamp":1651308270674,"user_tz":-540,"elapsed":261,"user":{"displayName":"이진하","userId":"09853356890937709334"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 예측 모델 설정\n","def predict(predict_sentence):\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","            if np.argmax(logits) == 0:  emotion = '당황'\n","            elif np.argmax(logits) == 1: emotion = '기쁨'\n","            elif np.argmax(logits) == 2: emotion = '슬픔'\n","            elif np.argmax(logits) == 3: emotion = '분노'\n","            elif np.argmax(logits) == 4: emotion = '상처'\n","            elif np.argmax(logits) == 5: emotion = '불안'\n","\n","        print(f'>> 입력한 내용: {emotion}')"],"metadata":{"id":"_wc0qNDi51ba","executionInfo":{"status":"ok","timestamp":1651308274309,"user_tz":-540,"elapsed":277,"user":{"displayName":"이진하","userId":"09853356890937709334"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#질문 무한반복하기! 0 입력시 종료\n","end = 1\n","while end == 1 :\n","    sentence = input('하고싶은 말을 입력해주세요 : ')\n","    if sentence == '0' :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXOErsgR6TwC","executionInfo":{"status":"ok","timestamp":1651308335476,"user_tz":-540,"elapsed":59180,"user":{"displayName":"이진하","userId":"09853356890937709334"}},"outputId":"c8a8b372-365c-4649-d52e-cb71bcdcb8d3"},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":["하고싶은 말을 입력해주세요 : 오늘 저녁 치맥 고?\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"name":"stdout","output_type":"stream","text":[">> 입력한 내용: 기쁨\n","\n","\n","하고싶은 말을 입력해주세요 : 하 오늘 친구랑 싸웠어\n",">> 입력한 내용: 당황\n","\n","\n","하고싶은 말을 입력해주세요 : 친구랑 싸웠어\n",">> 입력한 내용: 슬픔\n","\n","\n","하고싶은 말을 입력해주세요 : 오늘 지갑을 잃어버렸어 아무래도 지하철에서 떨어트린것 같아\n",">> 입력한 내용: 분노\n","\n","\n","하고싶은 말을 입력해주세요 : 짜증나 과제 너무 많아\n",">> 입력한 내용: 분노\n","\n","\n","하고싶은 말을 입력해주세요 : 0\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"lz8hGKAS6WGa"},"execution_count":null,"outputs":[]}]}